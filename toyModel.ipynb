{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9865149,"sourceType":"datasetVersion","datasetId":6055202}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mne\n!pip install mambapy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mne\nimport torch\nimport numpy as np\nimport torch.nn as nn\nfrom mne import set_config\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom mambapy.mamba import Mamba, MambaConfig\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nset_config('MNE_USE_CUDA', 'true')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.722472Z","iopub.execute_input":"2024-11-27T04:11:54.722814Z","iopub.status.idle":"2024-11-27T04:11:54.729305Z","shell.execute_reply.started":"2024-11-27T04:11:54.722783Z","shell.execute_reply":"2024-11-27T04:11:54.728445Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.730223Z","iopub.execute_input":"2024-11-27T04:11:54.730505Z","iopub.status.idle":"2024-11-27T04:11:54.749295Z","shell.execute_reply.started":"2024-11-27T04:11:54.730480Z","shell.execute_reply":"2024-11-27T04:11:54.748545Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_acq-clinical_run-1_ieeg.vhdr\n/kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_run-1_events.tsv\n/kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_acq-clinical_run-1_ieeg.eeg\n/kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_acq-clinical_run-1_ieeg.vmrk\n/kaggle/input/ieeg-data/sub-01_ses-iemu_acq-clinical_electrodes.tsv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Pre Process","metadata":{}},{"cell_type":"code","source":"def prepare_ieeg_data(eeg_file, window_size=1000, overlap=500, apply_filter=False):\n\n    raw = mne.io.read_raw_brainvision(eeg_file, preload=True)\n\n    if apply_filter:\n        raw.filter(l_freq=1, h_freq=200)  # Band-pass filter\n        raw.notch_filter(freqs=[50, 60])   # Remove line noise\n    \n    data = raw.get_data()\n    \n    n_channels = data.shape[0]\n    n_samples = data.shape[1]\n    step = window_size - overlap\n    \n    n_windows = (n_samples - 2 * window_size) // step + 1\n    \n    X = np.zeros((n_windows, n_channels, window_size))\n    y = np.zeros((n_windows, n_channels, window_size))\n    \n    for i in range(n_windows):\n        start_x = i * step\n        end_x = start_x + window_size\n        \n        start_y = end_x\n        end_y = start_y + window_size\n        \n        X[i] = data[:, start_x:end_x]\n        y[i] = data[:, start_y:end_y]\n    \n    return X, y, raw.ch_names\n\ndef extract_features(X):\n\n    mean = np.mean(X, axis=2)\n    std = np.std(X, axis=2)\n    max_val = np.max(X, axis=2)\n    min_val = np.min(X, axis=2)\n    \n    fft_vals = np.abs(np.fft.fft(X, axis=2))\n    freq_mean = np.mean(fft_vals, axis=2)\n    freq_std = np.std(fft_vals, axis=2)\n    \n    features = np.concatenate([\n        mean, std, max_val, min_val,\n        freq_mean, freq_std\n    ], axis=1)\n    \n    return features\n\ndef prepare_for_modeling(eeg_file, test_size=0.2, random_state=42, feature_type='raw'):\n\n    X, y, channels = prepare_ieeg_data(eeg_file)\n    \n    if feature_type == 'extracted':\n        \n        X = extract_features(X)\n        y = extract_features(y)\n        \n        scaler_X = StandardScaler()\n        scaler_y = StandardScaler()\n        \n        X = scaler_X.fit_transform(X)\n        y = scaler_y.fit_transform(y)\n    else:  # 'raw'\n\n        for i in range(X.shape[1]):\n            scaler = StandardScaler()\n            X[:, i, :] = scaler.fit_transform(X[:, i, :])\n            y[:, i, :] = scaler.transform(y[:, i, :])\n\n    train_idx = int(len(X) * (1 - test_size))\n    \n    X_train = X[:train_idx]\n    X_test = X[train_idx:]\n    y_train = y[:train_idx]\n    y_test = y[train_idx:]\n    \n    return X_train, X_test, y_train, y_test, channels\n\ndef prepare_dataset (X_train, X_test):\n    \n    from torch.utils.data import TensorDataset, DataLoader\n    \n    X_train = torch.tensor(X_train, dtype=torch.float32)\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    \n    train_dataset = TensorDataset(X_train, X_train)\n    test_dataset = TensorDataset(X_test, X_test)\n    \n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n    \n    return train_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.751156Z","iopub.execute_input":"2024-11-27T04:11:54.751410Z","iopub.status.idle":"2024-11-27T04:11:54.763500Z","shell.execute_reply.started":"2024-11-27T04:11:54.751386Z","shell.execute_reply":"2024-11-27T04:11:54.762664Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"code","source":"def train_model(\n    model, train_loader, test_loader, criterion, optimizer, num_epochs, device\n):\n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        \n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            \n            # Forward pass\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            \n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        train_loss /= len(train_loader)\n        \n        # Evaluation phase\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for X_batch, y_batch in test_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n                loss = criterion(outputs, y_batch)\n                test_loss += loss.item()\n        \n        test_loss /= len(test_loader)\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.764445Z","iopub.execute_input":"2024-11-27T04:11:54.764691Z","iopub.status.idle":"2024-11-27T04:11:54.777378Z","shell.execute_reply.started":"2024-11-27T04:11:54.764650Z","shell.execute_reply":"2024-11-27T04:11:54.776574Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"config = MambaConfig(d_model=1000, n_layers=2)\nmodel = Mamba(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.778434Z","iopub.execute_input":"2024-11-27T04:11:54.778789Z","iopub.status.idle":"2024-11-27T04:11:54.885773Z","shell.execute_reply.started":"2024-11-27T04:11:54.778753Z","shell.execute_reply":"2024-11-27T04:11:54.885075Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test, channels = prepare_for_modeling(\n    \"/kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_acq-clinical_run-1_ieeg.vhdr\",\n    feature_type='raw'  # or 'extracted' for feature-based prediction\n  )\n\nprint()  \nprint(f\"Training input shape: {X_train.shape}\")\nprint(f\"Training target shape: {y_train.shape}\")\nprint(f\"Test input shape: {X_test.shape}\")\nprint(f\"Test target shape: {y_test.shape}\")\nprint(f\"Number of channels: {len(channels)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:11:54.886977Z","iopub.execute_input":"2024-11-27T04:11:54.887324Z","iopub.status.idle":"2024-11-27T04:12:02.428626Z","shell.execute_reply.started":"2024-11-27T04:11:54.887290Z","shell.execute_reply":"2024-11-27T04:12:02.427728Z"}},"outputs":[{"name":"stdout","text":"Extracting parameters from /kaggle/input/ieeg-data/sub-01_ses-iemu_task-film_acq-clinical_run-1_ieeg.vhdr...\nSetting channel info structure...\nReading 0 ... 860253  =      0.000 ...   420.045 secs...\n\nTraining input shape: (1373, 111, 1000)\nTraining target shape: (1373, 111, 1000)\nTest input shape: (344, 111, 1000)\nTest target shape: (344, 111, 1000)\nNumber of channels: 111\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"train_loader, test_loader = prepare_dataset(X_train, X_test)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:12:02.429891Z","iopub.execute_input":"2024-11-27T04:12:02.430667Z","iopub.status.idle":"2024-11-27T04:12:02.784523Z","shell.execute_reply.started":"2024-11-27T04:12:02.430625Z","shell.execute_reply":"2024-11-27T04:12:02.783707Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"MambaModel = train_model(\n    model, \n    train_loader, \n    test_loader, \n    criterion, \n    optimizer, \n    num_epochs=2, \n    device='cuda'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:12:02.785660Z","iopub.execute_input":"2024-11-27T04:12:02.786031Z","iopub.status.idle":"2024-11-27T04:12:30.555265Z","shell.execute_reply.started":"2024-11-27T04:12:02.785993Z","shell.execute_reply":"2024-11-27T04:12:30.554381Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/2], Train Loss: 0.0004, Test Loss: 0.0000\nEpoch [2/2], Train Loss: 0.0000, Test Loss: 0.0000\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(MambaModel)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T04:12:30.557220Z","iopub.execute_input":"2024-11-27T04:12:30.557503Z","iopub.status.idle":"2024-11-27T04:12:30.562470Z","shell.execute_reply.started":"2024-11-27T04:12:30.557476Z","shell.execute_reply":"2024-11-27T04:12:30.561455Z"}},"outputs":[{"name":"stdout","text":"Mamba(\n  (layers): ModuleList(\n    (0-1): 2 x ResidualBlock(\n      (mixer): MambaBlock(\n        (in_proj): Linear(in_features=1000, out_features=4000, bias=False)\n        (conv1d): Conv1d(2000, 2000, kernel_size=(4,), stride=(1,), padding=(3,), groups=2000)\n        (x_proj): Linear(in_features=2000, out_features=95, bias=False)\n        (dt_proj): Linear(in_features=63, out_features=2000, bias=True)\n        (out_proj): Linear(in_features=2000, out_features=1000, bias=False)\n      )\n      (norm): RMSNorm()\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":31}]}